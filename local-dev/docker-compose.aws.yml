version: '3.8'
name: crawlinghub-aws

# ===============================================
# CrawlingHub - AWS 리소스 연결용 로컬 개발 환경
# ===============================================
# 사용법:
# 1. AWS SSM Session Manager로 RDS/Redis 포트 포워딩 설정
#    ./scripts/aws-port-forward.sh
# 2. docker-compose -f docker-compose.aws.yml up -d
#
# 포트 포워딩:
#   - localhost:13307 -> RDS (prod-shared-mysql)
#   - localhost:16379 -> ElastiCache (crawlinghub-redis-prod)
# ===============================================

services:
  # ===============================================
  # Application Services (AWS 리소스 연결)
  # ===============================================

  web-api:
    build:
      context: ..
      dockerfile: bootstrap/bootstrap-web-api/Dockerfile
    container_name: crawlinghub-web-api-aws
    env_file:
      - .env.aws
    environment:
      SPRING_PROFILES_ACTIVE: prod
      SERVER_PORT: 8080
      DB_HOST: host.docker.internal
      DB_PORT: 13307
      DB_NAME: ${DB_NAME:-crawler}
      DB_USERNAME: ${DB_USERNAME:-crawler_user}
      DB_PASSWORD: ${DB_PASSWORD}
      REDIS_HOST: host.docker.internal
      REDIS_PORT: 16379
      # NOTE: web-api에서는 SQS 직접 발행 비활성화
      # aws-sqs 모듈이 bootstrap-web-api에 포함되어 있지 않음
      # OutboxRetryScheduler(scheduler)가 PENDING 상태 Outbox를 처리함
      APP_MESSAGING_SQS_ENABLED: false
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    ports:
      - "8080:8080"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - crawlinghub-network
    restart: unless-stopped

  # ===============================================
  # Scheduler Service
  # ===============================================
  scheduler:
    build:
      context: ..
      dockerfile: bootstrap/bootstrap-scheduler/Dockerfile
    container_name: crawlinghub-scheduler-aws
    env_file:
      - .env.aws
    environment:
      SPRING_PROFILES_ACTIVE: prod
      SERVER_PORT: 8081
      DB_HOST: host.docker.internal
      DB_PORT: 13307
      DB_NAME: ${DB_NAME:-crawler}
      DB_USERNAME: ${DB_USERNAME:-crawler_user}
      DB_PASSWORD: ${DB_PASSWORD}
      REDIS_HOST: host.docker.internal
      REDIS_PORT: 16379
      # SQS Queue URLs (Listener)
      AWS_SQS_LISTENER_CRAWL_TASK_QUEUE_URL: https://sqs.ap-northeast-2.amazonaws.com/646886795421/prod-monitoring-sqs-crawlinghub-crawling-task
      AWS_SQS_LISTENER_EVENT_BRIDGE_TRIGGER_QUEUE_URL: https://sqs.ap-northeast-2.amazonaws.com/646886795421/prod-monitoring-sqs-crawlinghub-eventbridge-trigger
      # SQS Queue URLs (Publisher)
      SQS_CRAWL_TASK_QUEUE_URL: https://sqs.ap-northeast-2.amazonaws.com/646886795421/prod-monitoring-sqs-crawlinghub-crawling-task
      # Enable SQS messaging for CrawlTaskRegisteredEventListener
      APP_MESSAGING_SQS_ENABLED: true
      # Enable CrawlTask Outbox Retry Scheduler
      SCHEDULER_CRAWL_TASK_OUTBOX_ENABLED: true
      # Enable Session Issuance Scheduler (실제 세션 토큰 발급)
      SCHEDULER_SESSION_ISSUANCE_ENABLED: true
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    ports:
      - "8081:8081"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - crawlinghub-network
    restart: unless-stopped

  # ===============================================
  # Crawl Worker Service
  # ===============================================
  worker:
    build:
      context: ..
      dockerfile: bootstrap/bootstrap-crawl-worker/Dockerfile
    container_name: crawlinghub-worker-aws
    env_file:
      - .env.aws
    environment:
      SPRING_PROFILES_ACTIVE: prod
      SERVER_PORT: 8082
      DB_HOST: host.docker.internal
      DB_PORT: 13307
      DB_NAME: ${DB_NAME:-crawler}
      DB_USERNAME: ${DB_USERNAME:-crawler_user}
      DB_PASSWORD: ${DB_PASSWORD}
      REDIS_HOST: host.docker.internal
      REDIS_PORT: 16379
      # SQS Queue URLs (sqs-listener.yml property naming convention)
      SQS_CRAWL_TASK_QUEUE_URL: https://sqs.ap-northeast-2.amazonaws.com/646886795421/prod-monitoring-sqs-crawlinghub-crawling-task
      SQS_CRAWL_TASK_DLQ_URL: https://sqs.ap-northeast-2.amazonaws.com/646886795421/prod-monitoring-sqs-crawlinghub-crawling-task-dlq
      SQS_EVENTBRIDGE_TRIGGER_QUEUE_URL: https://sqs.ap-northeast-2.amazonaws.com/646886795421/prod-monitoring-sqs-crawlinghub-eventbridge-trigger
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
    ports:
      - "8082:8082"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - crawlinghub-network
    restart: unless-stopped

# ===============================================
# Networks
# ===============================================
networks:
  crawlinghub-network:
    driver: bridge
